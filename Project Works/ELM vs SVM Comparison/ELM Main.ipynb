{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8a487c",
   "metadata": {},
   "source": [
    "# Extreme Learning Machine (ELM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff415d",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe170603",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b0edec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Dataset/Concrete_Strength.csv\")\n",
    "\n",
    "def strength_class(x):\n",
    "    if x < 20:\n",
    "        return 0  # Low\n",
    "    elif x < 40:\n",
    "        return 1  # Medium\n",
    "    else:\n",
    "        return 2  # High\n",
    "\n",
    "df[\"Strength_Class\"] = df[\"Concrete_compressive_strength\"].apply(strength_class)\n",
    "\n",
    "# Features & target\n",
    "X = df.drop(columns=[\"Concrete_compressive_strength\", \"Strength_Class\"]).fillna(0.0)\n",
    "y = df[\"Strength_Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262f700",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66b19bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd904e",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2a89899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e067d7c",
   "metadata": {},
   "source": [
    "## Training the ELM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5383f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELMClassifier:\n",
    "    def __init__(self, input_dim, hidden_dim=500, activation='relu'):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.activation = activation\n",
    "        self.W = np.random.randn(input_dim, hidden_dim)\n",
    "        self.b = np.random.randn(hidden_dim)\n",
    "\n",
    "    def _activation(self, X):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-X))\n",
    "        elif self.activation == 'relu':\n",
    "            return np.maximum(0, X)\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_onehot = np.zeros((y.size, y.max() + 1))\n",
    "        y_onehot[np.arange(y.size), y] = 1\n",
    "        H = self._activation(np.dot(X, self.W) + self.b)\n",
    "        self.beta = np.linalg.pinv(H) @ y_onehot\n",
    "\n",
    "    def predict(self, X):\n",
    "        H = self._activation(np.dot(X, self.W) + self.b)\n",
    "        y_pred_prob = H @ self.beta\n",
    "        return np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "\n",
    "elm_clf = ELMClassifier(input_dim=X_train_scaled.shape[1], hidden_dim=500, activation='relu')\n",
    "elm_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b2fac0",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27b06604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š ELM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.62      0.82      0.70        39\n",
      "      Medium       0.75      0.78      0.76        91\n",
      "        High       0.81      0.63      0.71        76\n",
      "\n",
      "    accuracy                           0.73       206\n",
      "   macro avg       0.73      0.74      0.73       206\n",
      "weighted avg       0.75      0.73      0.73       206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = elm_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nðŸ“Š ELM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Low\", \"Medium\", \"High\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a3664",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8dd7583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[32  7  0]\n",
      " [ 9 71 11]\n",
      " [11 17 48]]\n",
      "Accuracy: 73.30%\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291abc7d",
   "metadata": {},
   "source": [
    "# ADMM Top 5 features(SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d4776",
   "metadata": {},
   "source": [
    "## ADMM Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23721d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected (Top-5 ADMM): ['Cement (component 1)(kg in a m^3 mixture)', 'Age (day)', 'Blast Furnace Slag (component 2)(kg in a m^3 mixture)', 'Fly Ash (component 3)(kg in a m^3 mixture)', 'Water  (component 4)(kg in a m^3 mixture)']\n"
     ]
    }
   ],
   "source": [
    "def select_top_k_via_admm(X, y, lam=0.01, rho=1.0, iters=200, k=5):\n",
    "    Xn = (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-12)\n",
    "    Xn = Xn.values if hasattr(Xn, \"values\") else np.asarray(Xn)\n",
    "    yv = y.values if hasattr(y, \"values\") else np.asarray(y)\n",
    "\n",
    "    n, p = Xn.shape\n",
    "    w = np.zeros(p)\n",
    "    z = np.zeros(p)\n",
    "    u = np.zeros(p)\n",
    "\n",
    "    XtX = Xn.T @ Xn\n",
    "    Xty = Xn.T @ yv\n",
    "    I = np.eye(p)\n",
    "\n",
    "    def soft_threshold(v, t):\n",
    "        return np.sign(v) * np.maximum(np.abs(v) - t, 0.0)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        w = np.linalg.solve(XtX + rho * I, Xty + rho * (z - u))\n",
    "        z = soft_threshold(w + u, lam / rho)\n",
    "        u = u + (w - z)\n",
    "\n",
    "    idx = np.argsort(-np.abs(z))[:k]\n",
    "    selected_cols = list(X.columns[idx])\n",
    "    return selected_cols\n",
    "\n",
    "top5_cols = select_top_k_via_admm(X_train, y_train, lam=0.01, rho=1.0, iters=300, k=5)\n",
    "print(\"Selected (Top-5 ADMM):\", top5_cols)\n",
    "\n",
    "X = X[top5_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109c0b4",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff072fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full feature matrix (no target columns)\n",
    "X_all = X\n",
    "y_cls_all = df[\"Strength_Class\"].to_numpy()\n",
    "y_reg_all = df[\"Concrete_compressive_strength\"].to_numpy()  # for feature selection (regression)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train_cls, y_test_cls, y_train_reg, y_test_reg = train_test_split(X_all, y_cls_all, y_reg_all, test_size=0.2, random_state=42, stratify=y_cls_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66c248",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b39badc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_scaler = StandardScaler()\n",
    "X_train_clf = clf_scaler.fit_transform(X_train)\n",
    "X_test_clf  = clf_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd6a58",
   "metadata": {},
   "source": [
    "## Training the ELM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "993b1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "elm = ELMClassifier(input_dim=X_train_clf.shape[1], hidden_dim=500, activation='relu')\n",
    "elm.fit(X_train_clf, y_train_cls)\n",
    "\n",
    "y_pred = elm.predict(X_test_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ad6da",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40ab3b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š ELM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.54      0.82      0.65        39\n",
      "      Medium       0.73      0.67      0.70        91\n",
      "        High       0.83      0.70      0.76        76\n",
      "\n",
      "    accuracy                           0.71       206\n",
      "   macro avg       0.70      0.73      0.70       206\n",
      "weighted avg       0.73      0.71      0.71       206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“Š ELM Classification Report:\")\n",
    "print(classification_report(y_test_cls, y_pred, target_names=[\"Low\", \"Medium\", \"High\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6e52c",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6ed08215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[32  7  0]\n",
      " [19 61 11]\n",
      " [ 8 15 53]]\n",
      "Accuracy: 70.87%\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_cls, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test_cls, y_pred) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
